{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Somewhere Diffusion.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMMslp9m/35HCFpiHwcMY+W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/somewheresy/somewhere-diffusion/blob/main/Somewhere_Diffusion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Somewhere Diffusion\n",
        "\n",
        "#### A notebook for training diffusion models on custom datasets with video and photo input, allowing users to synthesize novel images from those models, with Google Drive support and ESRGAN image upscaling.\n",
        "\n",
        "## Introduction\n",
        "Various methods for the generation of images using machine learning have rapidly expanded as they have become more accessible through services like [Midjourney](https://www.midjourney.com/home/) and OpenAI's [DALL-E 2](https://openai.com/dall-e-2/). However, controversy surrounding intellectual property rights of artists have created a schism in the creative community over the topic of \"AI Art\". \n",
        "\n",
        "This is in part due to private companies training models for image generation on datasets that may include copyrighted, or even illegal content (overlooked due to the size of the dataset being practically unmoderable, such as the case with LAION-400M) without the consent of the copyright holders.\n",
        "\n",
        "The intention of this notebook is to provide a tool which can be used for training models on any collection of images, changing the social contract of image generation into a consent-forward proposal. Although this notebook still utilizes OpenAI's CLIP for image-text pair retrieval, it is model-agnostic: allowing users to load whichever .pt model file they please instead of potentially blurring ethical lines of consent and ownership (unless, of course, users deliberately choose to do so).\n",
        "\n",
        "The purpose of the notebook is to allow traditional artists to automate parts of their process or act as a jumping-off point for them to develop new ways of using this tool, without worrying if they're feeding into a for-profit machine cannibalizing their work for monetary gain they are not receiving a portion of. In summary, the only remaining part of this tool which uses large (and opaque) image datasets will be CLIP -- *the onus will be on them, and not the AI Art community at large*.\n",
        "\n",
        "## Requirements\n",
        "\n",
        "At the current point in time, Colab Pro and a GPU with 16GB of RAM or more is needed. Optimizations will be pursued to allow this notebook to run on lower-end GPUs, with the intention of accessibility across the global software community.\n",
        "\n",
        "## Architecture / How-To\n",
        "\n",
        "TBD\n",
        "\n",
        "## Prior Art\n",
        "\n",
        "This notebook is constructed on methods initially developed by [un1tz3r0](https://linktr.ee/un1tz3r0), which themselves were based on a notebook by [Alex Spirin](https://twitter.com/devdef). The methods that are used for image generation using diffusion models largely are to the credit of [Katherine Crowson](https://twitter.com/RiversHaveWings) and [Advadnoun](https://twitter.com/advadnoun) who helped to pioneer the method of using CLIP and VQ-GAN together for image synthesis.\n",
        "\n",
        "The portion of this notebook which synthesizes images is adapted from my prior notebook, the [S2ML Image Generator](https://github.com/somewheresy/S2ML-Generators/blob/main/S2ML_Image_Generator.ipynb).\n",
        "## Research\n",
        "\n",
        "The end-state of this project will be a continuously repeatable research methodology for evaluating the subjective fidelity of this notebook, as well as perhaps a method for quantitatively validating the proximity of output images to the CLIP-embeddings in latent space. The research will live in the notebook as a means to foster accessibility. \n",
        "\n"
      ],
      "metadata": {
        "id": "aPxWoeSiHPYZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown #Check GPU/VRAM & RAM\n",
        "\n",
        "#@markdown ####If you receive an error that NVIDIA-SMI has failed, you will have to enable the GPU in the Notebook settings. Click on **Edit > Notebook Settings** and select GPU as hardware accelerator.\n",
        "\n",
        "from psutil import virtual_memory\n",
        "!nvidia-smi --query-gpu=gpu_name,gpu_bus_id,vbios_version --format=csv\n",
        "gpu_name = !nvidia-smi --query-gpu=gpu_name, --format=csv\n",
        "\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "1DBp2JqUP8sA",
        "outputId": "45855817-bc6b-444d-8f74-2f133cdeb10f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name, pci.bus_id, vbios_version\n",
            "Tesla P100-PCIE-16GB, 00000000:00:04.0, 86.00.52.00.02\n",
            "Your runtime has 13.6 gigabytes of available RAM\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Connect Google Drive\n",
        "import os\n",
        "\n",
        "## from https://svn.blender.org/svnroot/bf-blender/trunk/blender/build_files/scons/tools/bcolors.py\n",
        "class bcolors:\n",
        "    HEADER = '\\033[95m'\n",
        "    OKBLUE = '\\033[94m'\n",
        "    OKCYAN = '\\033[96m'\n",
        "    OKGREEN = '\\033[92m'\n",
        "    WARNING = '\\033[93m'\n",
        "    FAIL = '\\033[91m'\n",
        "    ENDC = '\\033[0m'\n",
        "    BOLD = '\\033[1m'\n",
        "    UNDERLINE = '\\033[4m'\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "root_path = \"/content/drive\"\n",
        "\n",
        "def checkRootPath():\n",
        "    if len(root_path) > 0:\n",
        "        os.chdir(root_path) # Changes directory to absolute root path\n",
        "        print(bcolors.BOLD + \"Root Path Check: \" + bcolors.OKBLUE)\n",
        "        !pwd\n",
        "\n",
        "checkRootPath()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pdy9zHbV7K5",
        "outputId": "bb0b5c61-7165-4f50-8699-218b613dc806"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\u001b[1mRoot Path Check: \u001b[94m\n",
            "/content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Make a workspace for Somewhere Diffusion, a project folder & set path to that folder\n",
        "#@markdown #### In the case the project folder already exists, you can use this block to set the directory to a previous project.\n",
        "workspace_name = \"Somewhere Diffusion\" #@param {type: \"string\"}\n",
        "root_path = \"/content\"\n",
        "if len(workspace_name) > 0:\n",
        "    path_tmp = root_path + \"/drive/MyDrive/\" + workspace_name\n",
        "    if not os.path.exists(path_tmp):\n",
        "        os.mkdir(path_tmp)\n",
        "        print(\"Created folder & set root path to: \" + root_path)\n",
        "    root_path = path_tmp\n",
        "print(\"Work & set root path to: \" + root_path)\n",
        "project_name = \"Notebook Development\" #@param {type: \"string\"}\n",
        "if len(project_name) > 0:\n",
        "      path_tmp = root_path + \"/\" + project_name\n",
        "      if not os.path.exists(path_tmp):\n",
        "          os.mkdir(path_tmp)\n",
        "      _path = path_tmp\n",
        "print(bcolors.BOLD + \"Created project subfolder & set root path to: \" + bcolors.OKBLUE + _path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJSG_MqTZhaK",
        "outputId": "e568ee53-06d6-46fd-862c-14171a8c176f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created folder & set root path to: /content\n",
            "\u001b[1mCreated project subfolder & set root path to: \u001b[94m/content/drive/MyDrive/Somewhere Diffusion/Notebook Development\n"
          ]
        }
      ]
    }
  ]
}